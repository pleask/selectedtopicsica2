{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Topics in Statistics ICA 2 - Patrick Leask\n",
    "\n",
    "## Task A1\n",
    "\n",
    "*1) Can we use the sommelier/ wine data to create an AI with super-human performance in wine tasting?*\n",
    "\n",
    "\n",
    "*2) Which components of wine make a wine a good wine?*\n",
    "- There may be interactions between components of wine that make it impossible to establish how variations in a single component affect the score with knowledge of the dependencies between the components.\n",
    "\n",
    "*3) Can the AI use the data to create the perfect wine, i.e. wine whose quality exceeds all that we have seen?*\n",
    "- As in the second question, I expect there to be complex interactions between the components of wine that do not allow extrapolation to regions that the AI does not have data for.\n",
    "- It is unlikely that the only factors in determining the quality of the wine are those in this data set. If we take water and chemicals to it until we matched the levels found in Chateau Lafite Rotschild, we will still not have created a wine. Even when starting with wine, rebalancing the qualities measured in the data will not necessarily create a better wine.\n",
    "- The question asks whether, given the data, the AI can create the perfect wine. This is a poorly worded question, as an entirely random wine generating process *can* create the perfect wine. A more precise question is whether the AI would know the ranges of values that would result in a rating of 10. We cannot answer this question with the data provided, and even if we had infinite data we must still consider the rating that is given to be a random variable and as such cannot say with certainty that the wine would receive a higher rating (see the next question).\n",
    "\n",
    "*4) Is human perception of wine entirely subjective? If so, what would it be that AIs could learn from humans?*\n",
    "- Human tastes are highly subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('precision', 3)\n",
    "\n",
    "wine_types = ['red', 'white']\n",
    "all_data = pd.concat([pd.read_csv(\"./winequality/winequality-{0}.csv\".format(wine_type), sep=';').assign(colour=wine_type) for wine_type in wine_types])\n",
    "all_data.head()\n",
    "\n",
    "numeric_titles = list(all_data)\n",
    "numeric_titles.remove('colour')\n",
    "numeric_titles.remove('quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "      <td>6497.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.319</td>\n",
       "      <td>5.443</td>\n",
       "      <td>0.056</td>\n",
       "      <td>30.525</td>\n",
       "      <td>115.745</td>\n",
       "      <td>0.995</td>\n",
       "      <td>3.219</td>\n",
       "      <td>0.531</td>\n",
       "      <td>10.492</td>\n",
       "      <td>5.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.145</td>\n",
       "      <td>4.758</td>\n",
       "      <td>0.035</td>\n",
       "      <td>17.749</td>\n",
       "      <td>56.522</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.009</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.987</td>\n",
       "      <td>2.720</td>\n",
       "      <td>0.220</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.038</td>\n",
       "      <td>17.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>3.110</td>\n",
       "      <td>0.430</td>\n",
       "      <td>9.500</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.310</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>29.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>0.995</td>\n",
       "      <td>3.210</td>\n",
       "      <td>0.510</td>\n",
       "      <td>10.300</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.390</td>\n",
       "      <td>8.100</td>\n",
       "      <td>0.065</td>\n",
       "      <td>41.000</td>\n",
       "      <td>156.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>3.320</td>\n",
       "      <td>0.600</td>\n",
       "      <td>11.300</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900</td>\n",
       "      <td>1.580</td>\n",
       "      <td>1.660</td>\n",
       "      <td>65.800</td>\n",
       "      <td>0.611</td>\n",
       "      <td>289.000</td>\n",
       "      <td>440.000</td>\n",
       "      <td>1.039</td>\n",
       "      <td>4.010</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14.900</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count       6497.000          6497.000     6497.000        6497.000   \n",
       "mean           7.215             0.340        0.319           5.443   \n",
       "std            1.296             0.165        0.145           4.758   \n",
       "min            3.800             0.080        0.000           0.600   \n",
       "25%            6.400             0.230        0.250           1.800   \n",
       "50%            7.000             0.290        0.310           3.000   \n",
       "75%            7.700             0.400        0.390           8.100   \n",
       "max           15.900             1.580        1.660          65.800   \n",
       "\n",
       "       chlorides  free sulfur dioxide  total sulfur dioxide   density  \\\n",
       "count   6497.000             6497.000              6497.000  6497.000   \n",
       "mean       0.056               30.525               115.745     0.995   \n",
       "std        0.035               17.749                56.522     0.003   \n",
       "min        0.009                1.000                 6.000     0.987   \n",
       "25%        0.038               17.000                77.000     0.992   \n",
       "50%        0.047               29.000               118.000     0.995   \n",
       "75%        0.065               41.000               156.000     0.997   \n",
       "max        0.611              289.000               440.000     1.039   \n",
       "\n",
       "             pH  sulphates   alcohol   quality  \n",
       "count  6497.000   6497.000  6497.000  6497.000  \n",
       "mean      3.219      0.531    10.492     5.818  \n",
       "std       0.161      0.149     1.193     0.873  \n",
       "min       2.720      0.220     8.000     3.000  \n",
       "25%       3.110      0.430     9.500     5.000  \n",
       "50%       3.210      0.510    10.300     6.000  \n",
       "75%       3.320      0.600    11.300     6.000  \n",
       "max       4.010      2.000    14.900     9.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_description = all_data.describe()\n",
    "\n",
    "display(data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "def col_hist(col_name):\n",
    "    \"\"\"\n",
    "    Plots a histogram for the column.\n",
    "    \"\"\"\n",
    "    col_max = all_data[col_name].max()\n",
    "    col_min = all_data[col_name].min()\n",
    "\n",
    "    step = (col_max - col_min) / 15\n",
    "\n",
    "    trace1 = go.Histogram(\n",
    "        x = all_data[all_data['colour']=='red'][col_name], \n",
    "        name = 'red'.title(),\n",
    "        opacity = 0.75,\n",
    "        xbins={\n",
    "            'start': col_min,\n",
    "            'end': col_max,\n",
    "            'size': step\n",
    "        },\n",
    "        histnorm='probability', \n",
    "        marker={\n",
    "            'color':'#900020'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    trace2 = go.Histogram(\n",
    "        x = all_data[all_data['colour']=='white'][col_name],\n",
    "        name = 'white'.title(),\n",
    "        opacity = 0.75,\n",
    "        xbins={\n",
    "            'start': col_min,\n",
    "            'end': col_max,\n",
    "            'size': step\n",
    "        },\n",
    "        histnorm='probability', \n",
    "        marker={\n",
    "            'color':'#D1B78F'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    histogram_data = [trace1, trace2]\n",
    "    layout = go.Layout(\n",
    "        xaxis={\n",
    "            'title': col_name.title()\n",
    "        },\n",
    "        yaxis={\n",
    "            'title':'Proportion'\n",
    "        },\n",
    "        bargap=0.2,\n",
    "        bargroupgap=0.1\n",
    "    )\n",
    "    this_fig = go.Figure(data=histogram_data, layout=layout)\n",
    "    plotly.offline.iplot(this_fig)\n",
    "\n",
    "#hist_plots = [col_hist(col_name) for col_name in list(data_description)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the histograms indicate it may be useful to perform transforms on the data. From the law of mass action, we should transform all chemical balance ratios with the logarithm. This should improve performance for additive models, where we consider absolute, not proportional, change. The exceptions are listed below, as they already appear to be normally distributed, or at least not exponentially skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_exceptions = [\n",
    "    'volatile acidity',\n",
    "    'total sulfur dioxide',\n",
    "    'density', \n",
    "    'ph',\n",
    "    'alcohol', \n",
    "    'citric acid'\n",
    "]\n",
    "\n",
    "remaining = [title for title in numeric_titles if title not in log_exceptions]\n",
    "\n",
    "all_data[remaining] = all_data[remaining].apply(np.sqrt)\n",
    "\n",
    "#hist_plots = [col_hist(col_name) for col_name in list(data_description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def col_scatter(col_name):\n",
    "    \"\"\"\n",
    "    Plots a histogram for the column.\n",
    "    \"\"\"\n",
    "    \n",
    "    trace1 = go.Scattergl(\n",
    "        x = all_data[all_data['colour']=='red'][col_name],\n",
    "        y = all_data[all_data['colour']=='red']['quality'],\n",
    "        name = 'red'.title(),\n",
    "        mode = 'markers',\n",
    "        marker={\n",
    "            'size': 10,\n",
    "            'color':'#900020',\n",
    "            'opacity': 0.1\n",
    "        }\n",
    "    )\n",
    "\n",
    "    trace2 = go.Scattergl(\n",
    "        x = all_data[all_data['colour']=='white'][col_name],\n",
    "        y = all_data[all_data['colour']=='white']['quality'],\n",
    "        name = 'white'.title(),\n",
    "        mode = 'markers',\n",
    "        marker={\n",
    "            'size': 10,\n",
    "            'color':'#D1B78F', \n",
    "            'opacity': 0.1\n",
    "        }\n",
    "    )\n",
    "\n",
    "    histogram_data = [trace1, trace2]\n",
    "    layout = go.Layout(\n",
    "        xaxis={\n",
    "            'title': col_name.title()\n",
    "        },\n",
    "        yaxis={\n",
    "            'title':'Quality'\n",
    "        },\n",
    "        bargap=0.2,\n",
    "        bargroupgap=0.1\n",
    "    )\n",
    "    this_fig = go.Figure(data=histogram_data, layout=layout)\n",
    "    plotly.offline.iplot(this_fig)\n",
    "    \n",
    "#scatter_plots = [col_scatter(col_name) for col_name in list(data_description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# axes = pd.plotting.scatter_matrix(all_data, alpha=0.2, figsize=(100, 150))\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('scatter_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process for tuning and validation\n",
    "- Split the data into a training and test set\n",
    "- On the training set, perform cross validation for fitting the models\n",
    "- Make predictions on the test set\n",
    "- Evaluate those predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def print_classification_results(clf, y_true, y_pred):\n",
    "    display(pd.DataFrame(clf.cv_results_))\n",
    "    \n",
    "    from sklearn.metrics import classification_report, accuracy_score\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print('Accuracy Score:', accuracy_score(y_true, y_pred))\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "def print_regression_results(reg, y_test, X_test):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(reg.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = reg.cv_results_['mean_test_score']\n",
    "    stds = reg.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, reg.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()   \n",
    "    \n",
    "    print('best cv', math.sqrt(-reg.best_score_))\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"best test\", mean_squared_error(y_test, reg.predict(X_test)))\n",
    "    \n",
    "    \n",
    "    display(pd.DataFrame({'true':y_test, 'pred': reg.predict(X_test)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "all_data[numeric_titles] = scale(all_data[numeric_titles])\n",
    "\n",
    "no_colour = all_data.drop(['colour'], axis=1)\n",
    "\n",
    "def data_split(data):\n",
    "    y = data['quality']\n",
    "    X = data.drop(\"quality\", axis=1)\n",
    "    \n",
    "    return train_test_split(\n",
    "        X, y, test_size=0.4, random_state=0\n",
    "    )\n",
    "\n",
    "# testing it without colour\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(no_colour)\n",
    "\n",
    "# testing with a subset \n",
    "X_train = X_train[:]\n",
    "y_train = y_train[:]\n",
    "\n",
    "# # testing just with svm\n",
    "# svc_pars = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# svc = GridSearchCV(SVC(), svc_pars, cv=3)\n",
    "# svc.fit(X_train, y_train)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rfc_pars = [{}]\n",
    "\n",
    "# rfc = GridSearchCV(RandomForestClassifier(), rfc_pars, cv=3)\n",
    "# rfc.fit(X_train, y_train)\n",
    "    \n",
    "# print_classification_results(clf, y_true, y_pred)\n",
    "# print_classification_results(rfc, y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] kernel=poly, gamma=3.0517578125e-05, C=256 ......................\n",
      "[CV] kernel=poly, gamma=3.0517578125e-05, C=256 ......................\n",
      "[CV] kernel=poly, gamma=3.0517578125e-05, C=256 ......................\n",
      "[CV] kernel=poly, gamma=3.0517578125e-05, C=256 ......................\n",
      "[CV] kernel=poly, gamma=3.0517578125e-05, C=256 ......................\n",
      "[CV] kernel=sigmoid, gamma=1, C=32 ...................................\n",
      "[CV] kernel=sigmoid, gamma=1, C=32 ...................................\n",
      "[CV] kernel=sigmoid, gamma=1, C=32 ...................................\n",
      "[CV]  kernel=poly, gamma=3.0517578125e-05, C=256, score=-0.6800890606116397, total=   1.4s\n",
      "[CV] kernel=sigmoid, gamma=1, C=32 ...................................\n",
      "[CV]  kernel=poly, gamma=3.0517578125e-05, C=256, score=-0.7684604865082753, total=   2.1s\n",
      "[CV]  kernel=poly, gamma=3.0517578125e-05, C=256, score=-0.7207684903992321, total=   2.1s\n",
      "[CV] kernel=sigmoid, gamma=1, C=32 ...................................\n",
      "[CV] kernel=sigmoid, gamma=0.125, C=1024 .............................\n",
      "[CV]  kernel=poly, gamma=3.0517578125e-05, C=256, score=-0.7925403859604816, total=   2.2s\n",
      "[CV]  kernel=poly, gamma=3.0517578125e-05, C=256, score=-0.7669220498369758, total=   2.2s\n",
      "[CV] kernel=sigmoid, gamma=0.125, C=1024 .............................\n",
      "[CV] kernel=sigmoid, gamma=0.125, C=1024 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   5 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  kernel=sigmoid, gamma=1, C=32, score=-56304451.662957154, total=   5.5s\n",
      "[CV] kernel=sigmoid, gamma=0.125, C=1024 .............................\n",
      "[CV]  kernel=sigmoid, gamma=1, C=32, score=-52356521.87841981, total=   7.0s\n",
      "[CV] kernel=sigmoid, gamma=0.125, C=1024 .............................\n",
      "[CV]  kernel=sigmoid, gamma=1, C=32, score=-59872149.47617393, total=   7.2s\n",
      "[CV] kernel=sigmoid, gamma=0.00390625, C=512 .........................\n",
      "[CV]  kernel=sigmoid, gamma=0.125, C=1024, score=-2799851440.917983, total=   5.9s\n",
      "[CV] kernel=sigmoid, gamma=0.00390625, C=512 .........................\n",
      "[CV]  kernel=sigmoid, gamma=1, C=32, score=-54497504.056564055, total=   6.9s\n",
      "[CV] kernel=sigmoid, gamma=0.00390625, C=512 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  kernel=sigmoid, gamma=0.125, C=1024, score=-2771244001.5424128, total=   6.4s\n",
      "[CV] kernel=sigmoid, gamma=0.00390625, C=512 .........................\n",
      "[CV]  kernel=sigmoid, gamma=0.125, C=1024, score=-2757858206.6244054, total=   6.7s\n",
      "[CV] kernel=sigmoid, gamma=0.00390625, C=512 .........................\n",
      "[CV]  kernel=sigmoid, gamma=1, C=32, score=-56382150.21440843, total=   7.3s\n",
      "[CV] kernel=sigmoid, gamma=0.0001220703125, C=16384 ..................\n",
      "[CV]  kernel=sigmoid, gamma=0.125, C=1024, score=-2610987383.3912554, total=   7.0s\n",
      "[CV] kernel=sigmoid, gamma=0.0001220703125, C=16384 ..................\n",
      "[CV]  kernel=sigmoid, gamma=0.125, C=1024, score=-2729612370.7931237, total=   6.0s\n",
      "[CV] kernel=sigmoid, gamma=0.0001220703125, C=16384 ..................\n",
      "[CV]  kernel=sigmoid, gamma=0.00390625, C=512, score=-145.49173722090822, total=  11.2s\n",
      "[CV] kernel=sigmoid, gamma=0.0001220703125, C=16384 ..................\n",
      "[CV]  kernel=sigmoid, gamma=0.00390625, C=512, score=-69.66578333479075, total=  13.0s\n",
      "[CV]  kernel=sigmoid, gamma=0.00390625, C=512, score=-34.34192706263994, total=  12.2s\n",
      "[CV] kernel=sigmoid, gamma=0.0001220703125, C=16384 ..................\n",
      "[CV] kernel=sigmoid, gamma=2, C=1 ....................................\n",
      "[CV]  kernel=sigmoid, gamma=0.00390625, C=512, score=-37.31652007329221, total=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  17 tasks      | elapsed:   20.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] kernel=sigmoid, gamma=2, C=1 ....................................\n",
      "[CV]  kernel=sigmoid, gamma=0.00390625, C=512, score=-59.79835427220859, total=  12.1s\n",
      "[CV] kernel=sigmoid, gamma=2, C=1 ....................................\n",
      "[CV]  kernel=sigmoid, gamma=0.0001220703125, C=16384, score=-0.5582867353760751, total=  14.9s\n",
      "[CV] kernel=sigmoid, gamma=2, C=1 ....................................\n",
      "[CV]  kernel=sigmoid, gamma=2, C=1, score=-66124.30811776505, total=   5.7s\n",
      "[CV] kernel=sigmoid, gamma=2, C=1 ....................................\n",
      "[CV]  kernel=sigmoid, gamma=2, C=1, score=-61713.05911494825, total=   6.6s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=64 ................................\n",
      "[CV]  kernel=sigmoid, gamma=2, C=1, score=-68292.97982765884, total=   7.1s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=64 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  24 tasks      | elapsed:   28.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  kernel=sigmoid, gamma=0.0001220703125, C=16384, score=-0.5090954251455305, total=  15.9s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=64 ................................\n",
      "[CV]  kernel=sigmoid, gamma=0.0001220703125, C=16384, score=-0.5218591685091672, total=  16.4s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=64 ................................\n",
      "[CV]  kernel=sigmoid, gamma=2, C=1, score=-65685.28982616334, total=   7.9s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=64 ................................\n",
      "[CV]  kernel=sigmoid, gamma=2, C=1, score=-61865.22559598792, total=   6.8s\n",
      "[CV] kernel=poly, gamma=0.03125, C=64 ................................\n",
      "[CV]  kernel=sigmoid, gamma=0.0001220703125, C=16384, score=-0.4629947473369776, total=  15.1s\n",
      "[CV] kernel=poly, gamma=0.03125, C=64 ................................\n",
      "[CV]  kernel=sigmoid, gamma=0.0001220703125, C=16384, score=-0.5322388500891814, total=  16.1s\n",
      "[CV] kernel=poly, gamma=0.03125, C=64 ................................\n",
      "[CV]  kernel=rbf, gamma=0.015625, C=64, score=-0.47831228524849667, total=  11.9s\n",
      "[CV] kernel=poly, gamma=0.03125, C=64 ................................\n",
      "[CV]  kernel=rbf, gamma=0.015625, C=64, score=-0.472153482104515, total=  13.9s\n",
      "[CV]  kernel=rbf, gamma=0.015625, C=64, score=-0.45505140811579475, total=  12.6s\n",
      "[CV] kernel=poly, gamma=0.03125, C=64 ................................\n",
      "[CV] kernel=rbf, gamma=0.015625, C=2 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  33 tasks      | elapsed:   41.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  kernel=rbf, gamma=0.015625, C=64, score=-0.41647720007044947, total=  13.0s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=2 .................................\n",
      "[CV]  kernel=rbf, gamma=0.015625, C=64, score=-0.4732003619922087, total=  13.7s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=2 .................................\n",
      "[CV]  kernel=rbf, gamma=0.015625, C=2, score=-0.49201430571091476, total=   4.8s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=2 .................................\n",
      "[CV]  kernel=rbf, gamma=0.015625, C=2, score=-0.4796977694398022, total=   5.4s\n",
      "[CV] kernel=rbf, gamma=0.015625, C=2 .................................\n",
      "[CV]  kernel=poly, gamma=0.03125, C=64, score=-0.5918390840970345, total=  14.9s\n",
      "[CV] kernel=poly, gamma=0.00390625, C=256 ............................\n",
      "[CV]  kernel=poly, gamma=0.00390625, C=256, score=-0.605006916622956, total=   2.5s\n",
      "[CV] kernel=poly, gamma=0.00390625, C=256 ............................\n",
      "[CV]  kernel=rbf, gamma=0.015625, C=2, score=-0.470518578545506, total=   4.9s\n",
      "[CV] kernel=poly, gamma=0.00390625, C=256 ............................\n",
      "[CV]  kernel=poly, gamma=0.03125, C=64, score=-0.5396829641701607, total=  15.3s\n",
      "[CV] kernel=poly, gamma=0.00390625, C=256 ............................\n",
      "[CV]  kernel=rbf, gamma=0.015625, C=2, score=-0.425822921286385, total=   5.2s\n",
      "[CV] kernel=poly, gamma=0.00390625, C=256 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:   52.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  kernel=rbf, gamma=0.015625, C=2, score=-0.49174958843554367, total=   4.6s\n",
      "[CV]  kernel=poly, gamma=0.00390625, C=256, score=-0.5905956628596396, total=   3.0s\n",
      "[CV]  kernel=poly, gamma=0.03125, C=64, score=-0.5694817265571347, total=  18.7s\n",
      "[CV]  kernel=poly, gamma=0.00390625, C=256, score=-0.5839246570380889, total=   3.3s\n",
      "[CV]  kernel=poly, gamma=0.00390625, C=256, score=-0.5466767769151896, total=   2.9s\n",
      "[CV]  kernel=poly, gamma=0.00390625, C=256, score=-0.6138470498545315, total=   3.3s\n",
      "[CV]  kernel=poly, gamma=0.03125, C=64, score=-0.7960832425573161, total=  16.3s\n",
      "[CV]  kernel=poly, gamma=0.03125, C=64, score=-0.5282235344173725, total=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:   58.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'gamma': 0.015625, 'C': 64}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-0.746 (+/-0.080) for {'kernel': 'poly', 'gamma': 3.0517578125e-05, 'C': 256}\n",
      "-55882782.614 (+/-4956506.859) for {'kernel': 'sigmoid', 'gamma': 1, 'C': 32}\n",
      "-2733943318.316 (+/-130952354.238) for {'kernel': 'sigmoid', 'gamma': 0.125, 'C': 1024}\n",
      "-69.312 (+/-80.677) for {'kernel': 'sigmoid', 'gamma': 0.00390625, 'C': 512}\n",
      "-0.517 (+/-0.063) for {'kernel': 'sigmoid', 'gamma': 0.0001220703125, 'C': 16384}\n",
      "-64736.666 (+/-5127.596) for {'kernel': 'sigmoid', 'gamma': 2, 'C': 1}\n",
      "-0.459 (+/-0.045) for {'kernel': 'rbf', 'gamma': 0.015625, 'C': 64}\n",
      "-0.605 (+/-0.196) for {'kernel': 'poly', 'gamma': 0.03125, 'C': 64}\n",
      "-0.472 (+/-0.049) for {'kernel': 'rbf', 'gamma': 0.015625, 'C': 2}\n",
      "-0.588 (+/-0.046) for {'kernel': 'poly', 'gamma': 0.00390625, 'C': 256}\n",
      "\n",
      "best cv 0.6775295073864251\n",
      "best test 0.519414908249\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>5.508</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>6.325</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>5.779</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.886</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>6.377</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>5.948</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>6.187</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>5.175</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>5.734</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>6.137</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>6.144</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>6.119</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>6.299</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>4.904</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>6.295</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>6.832</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>5.745</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4.909</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>5.603</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>6.921</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>6.448</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>5.661</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6.900</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>5.539</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>5.676</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>6.116</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>5.602</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>5.652</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>4.357</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.417</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>5.549</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>6.252</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>5.125</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>6.503</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>6.000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>5.484</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>7.216</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>4.950</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>5.511</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>5.670</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>4.981</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>5.232</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>6.080</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>4.885</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>5.929</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>6.051</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>6.069</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>6.361</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>5.317</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>6.648</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>6.040</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>6.015</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>5.088</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>5.858</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>5.571</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.103</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>4.933</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>5.876</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>6.085</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>6.061</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred  true\n",
       "3717  5.508     6\n",
       "3611  6.325     6\n",
       "1919  5.779     6\n",
       "23    4.886     5\n",
       "844   6.377     8\n",
       "1922  5.948     5\n",
       "3612  6.187     6\n",
       "3337  5.175     6\n",
       "1161  5.734     6\n",
       "4394  6.137     6\n",
       "1035  6.144     7\n",
       "2189  6.119     6\n",
       "1531  6.299     7\n",
       "864   4.904     5\n",
       "3198  6.295     7\n",
       "973   6.832     7\n",
       "1798  5.745     6\n",
       "311   4.909     6\n",
       "4805  5.603     6\n",
       "882   6.921     6\n",
       "3735  6.448     6\n",
       "3446  5.661     6\n",
       "502   6.900     7\n",
       "218   5.539     5\n",
       "2835  5.676     6\n",
       "2217  6.116     6\n",
       "2716  5.602     5\n",
       "2843  5.652     6\n",
       "170   4.357     4\n",
       "149   5.417     6\n",
       "...     ...   ...\n",
       "1194  5.549     6\n",
       "192   6.252     6\n",
       "2080  5.125     5\n",
       "900   6.503     5\n",
       "884   6.000     6\n",
       "4610  5.484     6\n",
       "3962  7.216     7\n",
       "3022  4.950     5\n",
       "1608  5.511     5\n",
       "2579  5.670     6\n",
       "2172  4.981     5\n",
       "201   5.232     5\n",
       "2844  6.080     5\n",
       "1478  4.885     3\n",
       "2357  5.929     5\n",
       "1829  6.051     7\n",
       "498   6.069     8\n",
       "4758  6.361     6\n",
       "800   5.317     6\n",
       "1104  6.648     6\n",
       "343   6.040     5\n",
       "774   6.015     9\n",
       "794   5.088     5\n",
       "2758  5.858     6\n",
       "1589  5.571     6\n",
       "23    5.103     5\n",
       "450   4.933     5\n",
       "2837  5.876     6\n",
       "2881  6.085     7\n",
       "708   6.061     6\n",
       "\n",
       "[2599 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "def fitter(model, params, samples, X_train, y_train):\n",
    "    model = RandomizedSearchCV(\n",
    "        model(), params, cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_iter=samples,\n",
    "        n_jobs=8,\n",
    "        pre_dispatch=8,\n",
    "        random_state = 0,\n",
    "        verbose=10,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# svr_pars = {\n",
    "#     'kernel': ['poly','sigmoid','rbf'], \n",
    "#     'gamma': [2**(x) for x in range(-15, 4)],\n",
    "#     'C': [2**(x) for x in range(-4, 15)]\n",
    "# }\n",
    "# svr = fitter(SVR, svr_pars, 10, X_train, y_train)\n",
    "\n",
    "# # dummy_pars = {}\n",
    "# # dum = fitter(DummyRegressor, dummy_pars, 1, X_train, y_train)\n",
    "\n",
    "# print_regression_results(svr, y_test, X_test)\n",
    "# print_regression_results(dum, y_true, y_pred, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=11, min_samples_split=2 ............................\n",
      "[CV] n_estimators=11, min_samples_split=2 ............................\n",
      "[CV] n_estimators=11, min_samples_split=2 ............................\n",
      "[CV] n_estimators=11, min_samples_split=2 ............................\n",
      "[CV] n_estimators=11, min_samples_split=2 ............................\n",
      "[CV] n_estimators=11, min_samples_split=3 ............................\n",
      "[CV] n_estimators=11, min_samples_split=3 ............................\n",
      "[CV] n_estimators=11, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=11, min_samples_split=3, score=-0.4242244354971628, total=   1.4s\n",
      "[CV] n_estimators=11, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=11, min_samples_split=3, score=-0.4255054900006198, total=   1.5s\n",
      "[CV] n_estimators=11, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=11, min_samples_split=2, score=-0.42280144098325917, total=   1.6s\n",
      "[CV]  n_estimators=11, min_samples_split=3, score=-0.4356343828730192, total=   1.6s\n",
      "[CV] n_estimators=13, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=11, min_samples_split=2, score=-0.4466412375503284, total=   1.6s\n",
      "[CV] n_estimators=13, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=11, min_samples_split=2, score=-0.4446047592272356, total=   1.6s\n",
      "[CV]  n_estimators=11, min_samples_split=2, score=-0.43160627251536343, total=   1.6s\n",
      "[CV] n_estimators=13, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=11, min_samples_split=2, score=-0.3835920177383591, total=   1.7s\n",
      "[CV] n_estimators=13, min_samples_split=3 ............................\n",
      "[CV] n_estimators=13, min_samples_split=3 ............................\n",
      "[CV] n_estimators=14, min_samples_split=3 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   5 tasks      | elapsed:    1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=13, min_samples_split=3, score=-0.384428845541959, total=   0.9s\n",
      "[CV] n_estimators=14, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=13, min_samples_split=3, score=-0.4230616009135662, total=   1.1s\n",
      "[CV] n_estimators=14, min_samples_split=3 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=11, min_samples_split=3, score=-0.47796092268230206, total=   1.7s\n",
      "[CV] n_estimators=14, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=13, min_samples_split=3, score=-0.42816699556978505, total=   1.7s\n",
      "[CV]  n_estimators=11, min_samples_split=3, score=-0.3951163726187066, total=   1.9s\n",
      "[CV] n_estimators=14, min_samples_split=3 ............................\n",
      "[CV] n_estimators=14, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=13, min_samples_split=3, score=-0.4238451234005968, total=   1.8s\n",
      "[CV] n_estimators=14, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=3, score=-0.4236610361112001, total=   1.9s\n",
      "[CV] n_estimators=14, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=13, min_samples_split=3, score=-0.4673599168761852, total=   2.0s\n",
      "[CV] n_estimators=14, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=3, score=-0.4204245945440142, total=   1.7s\n",
      "[CV] n_estimators=14, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=3, score=-0.4257150974160814, total=   1.9s\n",
      "[CV] n_estimators=14, min_samples_split=2 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  17 tasks      | elapsed:    4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=14, min_samples_split=3, score=-0.4476288190714883, total=   1.4s\n",
      "[CV] n_estimators=14, min_samples_split=2 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=3, score=-0.38017114701975735, total=   1.8s\n",
      "[CV] n_estimators=14, min_samples_split=2 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=4, score=-0.41664495554686554, total=   1.6s\n",
      "[CV] n_estimators=14, min_samples_split=2 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=4, score=-0.4200215602577979, total=   1.8s\n",
      "[CV] n_estimators=14, min_samples_split=2 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=4, score=-0.3776958984629009, total=   1.8s\n",
      "[CV] n_estimators=12, min_samples_split=2 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=4, score=-0.42277812760864425, total=   2.1s\n",
      "[CV] n_estimators=12, min_samples_split=2 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  24 tasks      | elapsed:    5.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=14, min_samples_split=4, score=-0.4521651993912582, total=   1.7s\n",
      "[CV] n_estimators=12, min_samples_split=2 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=2, score=-0.425, total=   1.6s\n",
      "[CV] n_estimators=12, min_samples_split=2 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=2, score=-0.43771585557299847, total=   1.6s\n",
      "[CV] n_estimators=12, min_samples_split=2 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=2, score=-0.42802851909994766, total=   1.4s\n",
      "[CV] n_estimators=13, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=12, min_samples_split=2, score=-0.4337072649572649, total=   1.2s\n",
      "[CV] n_estimators=13, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=12, min_samples_split=2, score=-0.4425480769230769, total=   1.5s\n",
      "[CV] n_estimators=13, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=2, score=-0.39228733855544784, total=   2.1s\n",
      "[CV] n_estimators=13, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=14, min_samples_split=2, score=-0.4518810091430668, total=   2.1s\n",
      "[CV] n_estimators=13, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=13, min_samples_split=4, score=-0.42611299771921896, total=   1.2s\n",
      "[CV] n_estimators=10, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=12, min_samples_split=2, score=-0.3718620738838967, total=   1.6s\n",
      "[CV] n_estimators=10, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=12, min_samples_split=2, score=-0.43873753561253553, total=   1.7s\n",
      "[CV] n_estimators=10, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=12, min_samples_split=2, score=-0.45105905006418484, total=   1.5s\n",
      "[CV] n_estimators=10, min_samples_split=4 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  33 tasks      | elapsed:    8.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=13, min_samples_split=4, score=-0.41943744785988196, total=   1.6s\n",
      "[CV] n_estimators=10, min_samples_split=4 ............................\n",
      "[CV]  n_estimators=13, min_samples_split=4, score=-0.3819970330831619, total=   1.4s\n",
      "[CV] n_estimators=12, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=10, min_samples_split=4, score=-0.39946151055629786, total=   1.0s\n",
      "[CV] n_estimators=12, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=10, min_samples_split=4, score=-0.43920760358927524, total=   1.3s\n",
      "[CV]  n_estimators=13, min_samples_split=4, score=-0.4479011286897501, total=   1.6s\n",
      "[CV] n_estimators=12, min_samples_split=3 ............................\n",
      "[CV]  n_estimators=13, min_samples_split=4, score=-0.44070600947430394, total=   2.0s\n",
      "[CV] n_estimators=12, min_samples_split=3 ............................\n",
      "[CV] n_estimators=12, min_samples_split=3 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:    9.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, min_samples_split=4, score=-0.4679290395704709, total=   1.0s\n",
      "[CV]  n_estimators=10, min_samples_split=4, score=-0.45188998368970096, total=   1.7s\n",
      "[CV]  n_estimators=10, min_samples_split=4, score=-0.43345435474082794, total=   1.8s\n",
      "[CV]  n_estimators=12, min_samples_split=3, score=-0.4402121864118392, total=   1.0s\n",
      "[CV]  n_estimators=12, min_samples_split=3, score=-0.420339471549541, total=   1.0s\n",
      "[CV]  n_estimators=12, min_samples_split=3, score=-0.44220333820662766, total=   1.0s\n",
      "[CV]  n_estimators=12, min_samples_split=3, score=-0.3927938570919976, total=   1.1s\n",
      "[CV]  n_estimators=12, min_samples_split=3, score=-0.42412268604319703, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:   10.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 14, 'min_samples_split': 4}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-0.426 (+/-0.046) for {'n_estimators': 11, 'min_samples_split': 2}\n",
      "-0.432 (+/-0.054) for {'n_estimators': 11, 'min_samples_split': 3}\n",
      "-0.425 (+/-0.053) for {'n_estimators': 13, 'min_samples_split': 3}\n",
      "-0.420 (+/-0.044) for {'n_estimators': 14, 'min_samples_split': 3}\n",
      "-0.418 (+/-0.047) for {'n_estimators': 14, 'min_samples_split': 4}\n",
      "-0.427 (+/-0.039) for {'n_estimators': 14, 'min_samples_split': 2}\n",
      "-0.428 (+/-0.057) for {'n_estimators': 12, 'min_samples_split': 2}\n",
      "-0.423 (+/-0.046) for {'n_estimators': 13, 'min_samples_split': 4}\n",
      "-0.438 (+/-0.046) for {'n_estimators': 10, 'min_samples_split': 4}\n",
      "-0.424 (+/-0.036) for {'n_estimators': 12, 'min_samples_split': 3}\n",
      "\n",
      "best cv 0.646422966714551\n",
      "best test 0.445504528737\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>5.595</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>6.214</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>5.714</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.857</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>7.417</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>5.740</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>6.089</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>5.643</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>5.565</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>6.179</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>5.967</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>6.060</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>5.798</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>5.000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>6.786</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>6.952</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>5.643</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>5.054</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>5.524</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>6.464</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>6.500</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>5.310</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6.973</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>5.214</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>5.631</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>5.857</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>6.071</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>5.750</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>5.030</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.726</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>5.565</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>6.214</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>5.196</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>6.214</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>5.589</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>5.786</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>6.714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>5.214</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>5.030</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>5.690</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>4.524</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>5.071</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>5.914</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>5.054</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>6.089</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>6.036</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>6.310</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>6.492</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>5.112</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>6.143</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>5.905</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>5.643</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>5.238</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>5.250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>6.607</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.071</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>5.429</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>5.310</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>6.500</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>5.786</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred  true\n",
       "3717  5.595     6\n",
       "3611  6.214     6\n",
       "1919  5.714     6\n",
       "23    4.857     5\n",
       "844   7.417     8\n",
       "1922  5.740     5\n",
       "3612  6.089     6\n",
       "3337  5.643     6\n",
       "1161  5.565     6\n",
       "4394  6.179     6\n",
       "1035  5.967     7\n",
       "2189  6.060     6\n",
       "1531  5.798     7\n",
       "864   5.000     5\n",
       "3198  6.786     7\n",
       "973   6.952     7\n",
       "1798  5.643     6\n",
       "311   5.054     6\n",
       "4805  5.524     6\n",
       "882   6.464     6\n",
       "3735  6.500     6\n",
       "3446  5.310     6\n",
       "502   6.973     7\n",
       "218   5.214     5\n",
       "2835  5.631     6\n",
       "2217  5.857     6\n",
       "2716  6.071     5\n",
       "2843  5.750     6\n",
       "170   5.030     4\n",
       "149   5.726     6\n",
       "...     ...   ...\n",
       "1194  5.565     6\n",
       "192   6.214     6\n",
       "2080  5.196     5\n",
       "900   6.214     5\n",
       "884   5.589     6\n",
       "4610  5.786     6\n",
       "3962  6.714     7\n",
       "3022  5.214     5\n",
       "1608  5.030     5\n",
       "2579  5.690     6\n",
       "2172  4.524     5\n",
       "201   5.071     5\n",
       "2844  5.914     5\n",
       "1478  5.054     3\n",
       "2357  6.089     5\n",
       "1829  6.036     7\n",
       "498   6.310     8\n",
       "4758  6.492     6\n",
       "800   5.112     6\n",
       "1104  6.143     6\n",
       "343   5.905     5\n",
       "774   5.643     9\n",
       "794   5.238     5\n",
       "2758  5.250     6\n",
       "1589  6.607     6\n",
       "23    5.071     5\n",
       "450   5.429     5\n",
       "2837  5.310     6\n",
       "2881  6.500     7\n",
       "708   5.786     6\n",
       "\n",
       "[2599 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# rfr_params = {\n",
    "#     'n_estimators':[x for x in range(10, 15)],\n",
    "#     'min_samples_split':[x for x in range(2,5)]\n",
    "# }\n",
    "\n",
    "# rfr = fitter(RandomForestRegressor, rfr_params, 10, X_train, y_train)\n",
    "# print_regression_results(rfr, y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
